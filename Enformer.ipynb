{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install enformer-pytorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "from Bio import SeqIO\n",
    "from enformer_pytorch import Enformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!gunzip ./Homo_sapiens.GRCh38.113.gtf.gz\n",
    "!gunzip ./Homo_sapiens.GRCh38.dna.primary_assembly.fa.gz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!head -6 Homo_sapiens.GRCh38.113.gtf | tail -1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!tail -50 Homo_sapiens.GRCh38.dna.primary_assembly.fa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#This extracts gene regions and saves them in a BED file format (chrom start end gene_info).\n",
    "\n",
    "!awk '$3 == \"gene\" {match($0, /gene_id \"([^\"]+)\"/, id); print \"chr\"$1 \"\\t\" $4-1 \"\\t\" $5 \"\\t\" id[1] \"\\t.\\t\" $7}' Homo_sapiens.GRCh38.113.gtf > genes.bed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!grep \"ENSG00000012048\" genes.bed > BRCA1.bed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conda install -c bioconda"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the genome FASTA into a dictionary\n",
    "fasta_file = \"Homo_sapiens.GRCh38.dna.primary_assembly.fa\"\n",
    "genome = SeqIO.to_dict(SeqIO.parse(fasta_file, \"fasta\"))\n",
    "\n",
    "# Read BED file\n",
    "bed_file = \"BRCA1.bed\"\n",
    "output_file = \"BRCA1_genes.fa\"\n",
    "\n",
    "with open(bed_file, \"r\") as bed, open(output_file, \"w\") as output:\n",
    "    for line in bed:\n",
    "        fields = line.strip().split(\"\\t\")\n",
    "        chrom, start, end, gene_id, score, strand = fields\n",
    "        \n",
    "        start, end = int(start), int(end)\n",
    "        \n",
    "        if chrom in genome:\n",
    "            seq = genome[chrom].seq[start:end]  # Extract sequence\n",
    "            if strand == \"-\":  # Reverse complement if on negative strand\n",
    "                seq = seq.reverse_complement()\n",
    "            \n",
    "            output.write(f\">{gene_id} {chrom}:{start}-{end}({strand})\\n{seq}\\n\")\n",
    "\n",
    "print(f\"Extracted sequences saved to {output_file}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now to perform one hot encoding "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def one_hot_encode(seq):\n",
    "    mapping = {'A': [1, 0, 0, 0], 'C': [0, 1, 0, 0], \n",
    "               'G': [0, 0, 1, 0], 'T': [0, 0, 0, 1], 'N': [0, 0, 0, 0]}\n",
    "    return np.array([mapping[base] for base in seq], dtype=np.uint8)\n",
    "\n",
    "# Load extracted sequences\n",
    "fasta_file = \"BRCA1_genes.fa\"\n",
    "sequences = []\n",
    "\n",
    "for record in SeqIO.parse(fasta_file, \"fasta\"):\n",
    "    seq = str(record.seq).upper()\n",
    "    if len(seq) >= 196608:  # Trim or pad to Enformer input size\n",
    "        seq = seq[:196608]\n",
    "    else:\n",
    "        seq += \"N\" * (196608 - len(seq))  # Pad with Ns\n",
    "\n",
    "    one_hot_seq = one_hot_encode(seq)\n",
    "    sequences.append(one_hot_seq)\n",
    "\n",
    "sequences = np.array(sequences)  # Convert to NumPy array\n",
    "np.save(\"one_hot_sequences_BRCA1_4.npy\", sequences)  # Save for later use\n",
    "\n",
    "print(\"One-hot encoded sequences saved as one_hot_sequences_BRCA1_4.npy\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.empty_cache()\n",
    "\n",
    "# Load saved one-hot encoded sequences\n",
    "data = np.load(\"one_hot_sequences_BRCA1_4.npy\")  # Shape: (batch_size, 196608, 4)\n",
    "\n",
    "# Convert to PyTorch tensor & reorder dimensions\n",
    "one_hot_tensor = torch.tensor(data, dtype=torch.float32).permute(0, 1, 2)  # (batch, 4, 196608)\n",
    "\n",
    "# Load Enformer model\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "model = Enformer.from_hparams(\n",
    "    dim=1536,\n",
    "    depth=11,\n",
    "    heads=8,\n",
    "    output_heads={\"human\": 5313},  \n",
    "    target_length=896\n",
    ").to(device)\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "one_hot_tensor = one_hot_tensor.to(device)  # Move tensor to GPU\n",
    "\n",
    "# Reduce batch size\n",
    "batch_size = 30  # Adjust based on available memory\n",
    "num_samples = one_hot_tensor.shape[0]\n",
    "\n",
    "model.eval()\n",
    "\n",
    "with torch.no_grad():\n",
    "    outputs = []\n",
    "    for i in range(0, num_samples, batch_size):\n",
    "        batch = one_hot_tensor[i:i+batch_size]  # Take a batch of sequences\n",
    "        output = model(batch)  # Forward pass\n",
    "        outputs.append(output[\"human\"].cpu().numpy())  # Store predictions\n",
    "\n",
    "# Combine results\n",
    "human_predictions = np.concatenate(outputs, axis=0)\n",
    "\n",
    "# Save predictions\n",
    "np.save(\"enformer_human_predictions.npy\", human_predictions)\n",
    "print(\"Predictions saved successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the .npy file\n",
    "data = np.load(\"enformer_human_predictions.npy\")\n",
    "\n",
    "# Check its shape and type\n",
    "print(\"Shape:\", data.shape)\n",
    "print(\"Data type:\", data.dtype)\n",
    "\n",
    "# Small portion of the data\n",
    "print(data[:5])  # First 5 elements (adjust based on your data)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
